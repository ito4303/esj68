---
title: "R, BUGS, Stanによる階層モデルのあてはめ"
author: "伊東宏樹"
date: "2021-03-21"
output:
  beamer_presentation:
    latex_engine: lualatex
    theme: metropolis
    keep_tex: true
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(AHMbook)
library(unmarked)
library(rjags)
library(cmdstanr)
options(mc.cores = parallel::detectCores())
```


## 今日の内容

- 占有モデル
    - 模擬データの作成
    - unmarked, JAGS, Stanによる当てはめ
- N混合モデル
    - 模擬データの作成
    - unmarked, JAGS, Stanによる当てはめ

# 占有モデル

## 模擬データの生成

```{r set_seed, include=FALSE}
set.seed(123)
```


```{r gen_site_occ_data, echo=TRUE}
occ_data <- AHMbook::simOcc(
  M = 300,                # Number of sites
  J = 2,                  # Number of temporal replicates
  mean.occupancy = 0.6,   # Mean occurrence
  beta1 = -2,             # Main effect of elev. on occ.
  beta2 = 2,              # Main effect of forest on occ.
  beta3 = 0,              # Interaction on occ. of elev. and forest
  mean.detection = 0.3,   # Mean detection prob.
  time.effects = c(0, 0), # Time effect
  alpha1 = 0,             # Main effect of elev. on det.
  alpha2 = -3,            # Main effect of wind speed on det.
  alpha3 = 0,             # Interaction on det. of elev and wind
  sd.lp = 0.5,            # S.D. of random site effects
  b = 0,                  # Behavioral response
  show.plot = FALSE)
```


## データの確認

```{r view_site_occ_data, echo=TRUE}
# True number of occupied sites
sum(occ_data$z)

# Observed number of occupied sites
sum(apply(occ_data$y, 1, max))
```

## データの確認

```{r view_site_occ_data3, echo=TRUE}
# Truth and observation of the first six sites
head(cbind(z = occ_data$z, occ_data$y))
```

# unmarkedによる占有モデルの当てはめ

## unmarkedオブジェクトの作成

```{r occ_unmarked, echo=TRUE, message=FALSE}
umf <- unmarkedFrameOccu(
  y = occ_data$y,
  siteCovs = data.frame(elev = occ_data$elev,
                        forest = occ_data$forest),
  obsCovs = list(wind = occ_data$wind))
```


## summary(umf)

```
unmarkedFrame Object

300 sites
Maximum number of observations per site: 2 
Mean number of observations per site: 2 
Sites with at least one detection: 93 

Tabulation of y observations:
  0   1 
493 107 
```

---

```
Site-level covariates:
      elev                forest         
 Min.   :-0.9987505   Min.   :-0.999069  
 1st Qu.:-0.4801063   1st Qu.:-0.467633  
 Median :-0.0408648   Median :-0.026556  
 Mean   :-0.0007763   Mean   :-0.002243  
 3rd Qu.: 0.4657950   3rd Qu.: 0.521011  
 Max.   : 0.9885396   Max.   : 0.998809  

Observation-level covariates:
      wind          
 Min.   :-0.997617  
 1st Qu.:-0.493880  
 Median : 0.007348  
 Mean   :-0.016454  
 3rd Qu.: 0.474305  
 Max.   : 0.989873  
```

## あてはめ

```{r occ_unmarked_fit, echo=TRUE}
fit_occ_unmarked <- occu(~ wind ~ elev + forest,
                         data = umf)
```

## 結果

```{r occ_unmarked_results, echo=TRUE}
print(fit_occ_unmarked)
```

<!--
```{r, echo=TRUE}
#backTransform(fm1, "state")
```
-->

<!--
```{r, echo=TRUE}
#backTransform(fm1, "det")
```
-->

# JAGSによる占有モデルの当てはめ

## JAGSモデル

```
model {
  for (m in 1:M) {
    logit(psi[m]) <- beta[1] + beta[2] * elev[m] + 
                     beta[3] * forest[m]
    z[m] ~ dbern(psi[m])
    for (j in 1:J) {
      logit(p[m, j]) <- alpha[1] + alpha[2] * wind[m, j]
      y[m, j] ~ dbern(z[m] * p[m, j])
    }
  }
  for (i in 1:3) {
    beta[i] ~ dnorm(0, 1.0e-2)
  }
  for (i in 1:2) {
    alpha[i] ~ dnorm(0, 1.0e-2)
  }
}
```

## Fit

```{r occ_jags, cache=TRUE, include=FALSE}
set.seed(1)
jags_data <- list(M = occ_data$M, J = occ_data$J, y = occ_data$y,
                  elev = occ_data$elev, forest = occ_data$forest,
                  wind = occ_data$wind)
ini_fun <- function() {
  list(beta = rnorm(3, 0, 2),
       alpha = rnorm(2, 0, 2),
       z = rep(1, occ_data$M))
}
mod_occ_jags <- jags.model("occ.txt", data = jags_data,
                           inits = ini_fun, n.chains = 3)
update(mod_occ_jags, 1000)
fit_occ_jags <- coda.samples(mod_occ_jags, n.iter = 1000,
                             variable.names = c("beta", "alpha"))
```

```{r}
summary(fit_occ_jags)
```


# Stanによる占有モデルの当てはめ

## Stanモデル

```
data {
  int<lower = 0> M;
  int<lower = 0> J;
  int<lower = 0, upper = 1> Y[M, J];
  vector[M] Elev;
  vector[M] Forest;
  matrix[M, J] Wind;
}
transformed data {
  int<lower = 0> Ysum[M];

  for (m in 1:M)
    Ysum[m] = sum(Y[m, ]);
}
```

---

```
parameters {
  vector[3] beta;
  vector[2] alpha;
}
transformed parameters {
  vector[M] logit_psi = beta[1]
                        + beta[2] * Elev
                        + beta[3] * Forest;
  matrix[M, J] logit_p = alpha[1]
                         + alpha[2] * Wind;
}
```

---

```
model {
  for (m in 1:M) {
    if (Ysum[m] > 0) { // detected
      target += bernoulli_logit_lpmf(1 | logit_psi[m])
              + bernoulli_logit_lpmf(Y[m, ] | logit_p[m, ]);
    } else {          // not detected
      real lp[2];

      lp[1] = bernoulli_logit_lpmf(0 | logit_psi[m]);
      lp[2] = bernoulli_logit_lpmf(1 | logit_psi[m])
            + bernoulli_logit_lpmf(Y[m, ] | logit_p[m, ]);
      target += log_sum_exp(lp);
    }
  }
  beta ~ normal(0, 10);
  alpha ~ normal(0, 10);
}
```

```{r occ_stan, cache=TRUE, include=FALSE}
stan_data <- list(M = occ_data$M, J = occ_data$J, Y = occ_data$y,
                  Elev = occ_data$elev, Forest = occ_data$forest,
                  Wind = occ_data$wind)
mod_occ_stan <- cmdstan_model("occ.stan")
output_dir <- "./"
fit_occ_stan <- mod_occ_stan$sample(data = stan_data, seed = 1,
                                    output_dir = output_dir,
                                    chains = 4, parallel_chains = 4,
                                    iter_sampling = 1000,
                                    iter_warmup = 1000,
                                    refresh = 500)
```

---

```{r}
fit_occ_stan$summary(c("beta", "alpha"))
```



# N-混合モデル

## データ

```{r, include=FALSE}
set.seed(123)
```

```{r nmix_data, echo=TRUE, message=FALSE}
nmix_data <- AHMbook::simNmix(
  nsites = 120,         # Number of sites
  nvisits = 2,          # Number of visits pre site
  mean.lam = 2,         # Expected abundance
  mean.p = 0.6,         # Expected detection
  beta2.lam = 0.5,      # Coef. of site covariate 2 in abundance model
  beta.p.survey = 0.8,  # Coef. of survey covariate on p
  show.plots = FALSE)
```


# unmarkedによるN混合モデルの当てはめ

## unmarkedオブジェクトの作成

```{r nmix_unmarked, echo=TRUE}
umf <- unmarkedFramePCount(
  y = nmix_data$C,
  siteCovs = data.frame(site_cov =
                          nmix_data$site.cov[, 2]),
  obsCovs = list(survey_cov = nmix_data$survey.cov))
```

## summary(umf)

```
unmarkedFrame Object

120 sites
Maximum number of observations per site: 2 
Mean number of observations per site: 2 
Sites with at least one detection: 100 

Tabulation of y observations:
 0  1  2  3  4  5  6 
69 86 44 26  9  4  2 
```

---

```
Site-level covariates:
    site_cov       
 Min.   :-1.95813  
 1st Qu.:-0.93791  
 Median :-0.08173  
 Mean   :-0.01629  
 3rd Qu.: 0.76828  
 Max.   : 1.94256  

Observation-level covariates:
   survey_cov      
 Min.   :-1.99523  
 1st Qu.:-0.97282  
 Median : 0.05019  
 Mean   :-0.01689  
 3rd Qu.: 0.97496  
 Max.   : 1.96868  
```

## Fit

```{r nmix_unmarked_fit, echo=TRUE}
fm2 <- pcount( ~ survey_cov ~ site_cov, data = umf, K = 110)
print(fm2)
```


# JAGSによるN混合モデルの当てはめ

## JAGS

```
model {
  for (m in 1:M) {
    log(lambda[m]) <- beta[1] + beta[2] * cov.abn[m]
    n[m] ~ dpois(lambda[m])
    for (j in 1:J) {
      logit(p[m, j]) <- alpha[1] +
                        alpha[2] * cov.det[m, j]
      y[m, j] ~ dbin(p[m, j], n[m])
    }
  }
  for (i in 1:2) {
    beta[i] ~ dnorm(0, 1.0e-2)
  }
  for (i in 1:2) {
    alpha[i] ~ dnorm(0, 1.0e-2)
  }
}
```

---

```{r nmix_jags, cache=TRUE, include=FALSE}
set.seed(1)
jags_data <- list(M = nmix_data$nsites, J = nmix_data$nvisits,
                  y = nmix_data$C,
                  cov.abn = nmix_data$site.cov[, 2],
                  cov.det = nmix_data$survey.cov)
ini_fun <- function() {
  list(beta = rnorm(2, 0, 2),
       alpha = rnorm(2, 0, 2),
       n = apply(nmix_data$C, 1, max))
}
mod_nmix_jags <- jags.model("nmix.txt", data = jags_data,
                            inits = ini_fun, n.chains = 3)
update(mod_nmix_jags, 1000)
fit_nmix_jags <- coda.samples(mod_nmix_jags, n.iter = 2000,
                              variable.names = c("beta", "alpha"))
```

```{r, echo=TRUE}
summary(fit_nmix_jags)
```


# StanによるN混合モデルの当てはめ

## Stan

```
data {
  int<lower = 0> M;
  int<lower = 0> J;
  int<lower = 0> Y[M, J];
  vector[M] Cov_abn;
  matrix[M, J] Cov_det;
  int<lower = 0> Max_N;
}
```

---

```
parameters {
  vector[2] beta;
  vector[2] alpha;
}

transformed parameters {
  vector[M] log_lambda = beta[1]
                         + beta[2] * Cov_abn;
  matrix[M, J] logit_p = alpha[1]
                         + alpha[2] * Cov_det;
}
```

---

```
model {
  for (m in 1:M) {
    int y_max = max(Y[m]);
    vector[Max_N + 1] lp;

    for (n in 0:(y_max - 1))
      lp[n + 1] = negative_infinity();
    for (n in y_max:Max_N)
      lp[n + 1] = poisson_log_lpmf(n | log_lambda[m])
                  + binomial_logit_lpmf(Y[m, ] | n, logit_p[m, ]);
    target += log_sum_exp(lp);
  }
  beta ~ normal(0, 10);
  alpha ~ normal(0, 10);
}
```

```{r nmix_stan_1, cache=TRUE, include=FALSE}
stan_data <- list(M = nmix_data$nsites, J = nmix_data$nvisits,
                  Y = nmix_data$C,
                  Cov_abn = nmix_data$site.cov[, 2],
                  Cov_det = nmix_data$survey.cov,
                  Max_N = max(nmix_data$C) + 100)
mod_nmix_stan_1 <- cmdstan_model("nmix.stan")
fit_nmix_stan_1 <- mod_nmix_stan_1$sample(
  data = stan_data, seed = 1,
  output_dir = output_dir,
  chains = 4, parallel_chains = 4,
  iter_sampling = 1000,
  iter_warmup = 1000,
  refresh = 500)
```

---

```{r}
fit_nmix_stan_1$summary(c("beta", "alpha"))
```

## Reduce Sum

```
functions {
  real n_mixture_log_lpmf(int[] count, int max_n,
                          real log_lambda, vector logit_p) {
                 
    int c_max = max(count);
    vector[max_n + 1] lp;

    for (k in 0:(c_max - 1))
      lp[k + 1] = negative_infinity();
    for (k in c_max:max_n) 
      lp[k + 1] = poisson_log_lpmf(k | log_lambda)
                  + binomial_logit_lpmf(count | k, logit_p);
    return log_sum_exp(lp);
  }
```

---

```
  real partial_sum(int[] site,
                   int start, int end,
                   int[, ] count,
                   int max_n,
                   vector log_lambda, matrix logit_p) {
    real lp = 0;

    for (m in start:end)
      lp = lp + n_mixture_log_lpmf(count[m] |
                                   max_n, log_lambda[m], logit_p[m, ]');
    return lp;
  }
}
```

---

```
model {
  int grainsize = 1;

  target += reduce_sum(partial_sum, site, grainsize, Y, Max_N,
                       log_lambda, logit_p);
  beta ~ normal(0, 10);
  alpha ~ normal(0, 10);
}
```


```{r nmix_stan_2, cache=TRUE, include=FALSE}
mod_nmix_stan_2 <- cmdstan_model(
  "nmix_rs.stan",
  cpp_options = list(stan_threads = TRUE))
fit_nmix_stan_2 <- mod_nmix_stan_2$sample(
  data = stan_data, seed = 1,
  output_dir = output_dir,
  chains = 4, parallel_chains = 4,
  threads_per_chain = 3,
  iter_sampling = 1000,
  iter_warmup = 1000,
  refresh = 500)
```

```{r}
fit_nmix_stan_2$summary(c("beta", "alpha"))
```

## Bivariate Poisson

```
functions {
  real bivariate_poisson_log_lpmf(int[] n, real log_lambda, vector p) {
    real s[min(n) + 1];
    real log_theta_2 = log_lambda + log(p[1]) + log1m(p[2]);
    real log_theta_1 = log_lambda + log1m(p[1]) + log(p[2]);
    real log_theta_0 = log_lambda + log(p[1]) + log(p[2]);

    if (size(n) != 2 || num_elements(p) != 2)
      reject("Size of n and p must be 2.");
    if (p[1] < 0 || p[1] > 1 || p[2] < 0 || p[2] > 1)
      reject("p must be in [0,1].");
    for (u in 0:min(n))
      s[u + 1] = poisson_log_lpmf(n[1] - u | log_theta_2)
               + poisson_log_lpmf(n[2] - u | log_theta_1)
               + poisson_log_lpmf(u | log_theta_0);
    return log_sum_exp(s);
  }
}
```

---

```
model {
  for (m in 1:M)
    Y[m, ] ~ bivariate_poisson_log(log_lambda[m], p[m, ]');
  beta ~ normal(0, 10);
  alpha ~ normal(0, 10);
}
```

```{r nmix_stan_3, cache=TRUE, include=FALSE}
mod_nmix_stan_3 <- cmdstan_model("nmix_bp.stan")
fit_nmix_stan_3 <- mod_nmix_stan_3$sample(
  data = stan_data, seed = 1,
  output_dir =output_dir,
  chains = 4, parallel_chains = 4,
  iter_sampling = 1000,
  iter_warmup = 1000,
  refresh = 500)
```


```{r}
fit_nmix_stan_3$summary(c("beta", "alpha"))
```



